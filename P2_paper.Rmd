---
title: "Melbourne Housing Market - Paper2"
subtitle: "Intro Data Science"
author: "Team 2"
date: "`r Sys.Date()`"
output:
   html_document:
     toc: true
     toc_float: true
     number_section: true
---



```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
knitr::opts_chunk$set(echo = F)
options(scientific=T, digits = 5) 
options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times

source("general_support.R", local = knitr::knit_global())
source("P2_support.R", local = knitr::knit_global())

```


```{r stats_libs, include=F}
# loadPkg("leaps")
# loadPkg("ggplot2")
# loadPkg("gridExtra")
# loadPkg("scales")
# loadPkg("heatmaply")
# loadPkg("Hmisc")
# loadPkg("faraway")
# loadPkg("jtools")
```


```{r data, include=F}

train <- load_data()
test <- load_data(F)

```




```{r, include=F}

loadPkg("xtable")
loadPkg("kableExtra")
loadPkg("stringi")

xkabledply = function(modelsmmrytable, title="Table", digits = 4, pos="left", bso="striped", wide=FALSE) { 
  #' Combining base::summary, xtable, and kableExtra, to easily display model summary. 
  #' wrapper for the base::summary function on model objects
  #' Can also use as head for better display
  #' ELo 202004 GWU DATS
  #' version 1.2
  #' @param modelsmmrytable This can be a generic table, a model object such as lm(), or the summary of a model object summary(lm()) 
  #' @param title Title of table. 
  #' @param digits Number of digits to display
  #' @param pos Position of table, c("left","center","right") 
  #' @param bso bootstrap_options = c("basic", "striped", "bordered", "hover", "condensed", "responsive")
  #' @param wide print table in long (FALSE) format or wide (TRUE) format
  #' @return HTML table for display
  #' @examples
  #' library("xtable")
  #' library("kableExtra")
  #' xkabledply( df, title="Table testing", pos="left", bso="hover" )
  #' xkabledply( ISLR::Hitters[1:5,] )
  if (wide) { modelsmmrytable <- t(modelsmmrytable) }
  modelsmmrytable %>%
    xtable() %>% 
    kable(caption = title, digits = digits) %>%
    kable_styling(bootstrap_options = bso, full_width = FALSE, position = pos)
}

xkabledplyhead = function(df, rows=5, title="Head", digits = 4, pos="left", bso="striped") { 
  xkabledply(df[1:rows, ], title, digits, pos, bso, wide=FALSE)
}

xkabledplytail = function(df, rows=5, title="Tail", digits = 4, pos="left", bso="striped") { 
  trows = nrow(df)
  xkabledply(df[ (trows-rows+1) : trows, ], title, digits, pos, bso, wide=FALSE)
}

xkablesummary = function(df, title="Table: Statistics summary.", digits = 4, pos="left", bso="striped") { 
  #' Combining base::summary, xtable, and kableExtra, to easily display numeric variable summary of dataframes. 
  #' ELo 202004 GWU DATS
  #' version 1.2
  #' @param df The dataframe.
  #' @param title Title of table. 
  #' @param digits Number of digits to display
  #' @param pos Position of table, c("left","center","right") 
  #' @param bso bootstrap_options = c("basic", "striped", "bordered", "hover", "condensed", "responsive")
  #' @return The HTML summary table for display, or for knitr to process into other formats 
  #' @examples
  #' xkablesummary( faraway::ozone )
  #' xkablesummary( ISLR::Hitters, title="Five number summary", pos="left", bso="hover"  )
  
  s = summary(df) %>%
    apply( 2, function(x) stringr::str_remove_all(x,c("Min.\\s*:\\s*","1st Qu.\\s*:\\s*","Median\\s*:\\s*","Mean\\s*:\\s*","3rd Qu.\\s*:\\s*","Max.\\s*:\\s*")) ) %>% # replace all leading words
    apply( 2, function(x) stringr::str_trim(x, "right")) # trim trailing spaces left
  
  colnames(s) <- stringr::str_trim(colnames(s))
  
  if ( dim(s)[1] ==6 ) { rownames(s) <- c('Min','Q1','Median','Mean','Q3','Max') 
  } else if ( dim(s)[1] ==7 ) { rownames(s) <- c('Min','Q1','Median','Mean','Q3','Max','NA') }
  
  xkabledply(s, title=title, digits = digits, pos=pos, bso=bso )
}


xkablevif = function(model, title="VIFs of the model", digits = 3, pos="left", bso="striped", wide=TRUE) { 
  #' Combining faraway::vif, xtable, and kableExtra, to easily display numeric summary of VIFs for a model. 
  #' ELo 202004 GWU DATS
  #' version 1.2
  #' @param model The lm or compatible model object.
  #' @param title Title of table. 
  #' @param digits Number of digits to display
  #' @param pos Position of table, c("left","center","right") 
  #' @param bso bootstrap_options = c("basic", "striped", "bordered", "hover", "condensed", "responsive")
  #' @param wide print table in long (FALSE) format or wide (TRUE) format
  #' @return The HTML summary table of the VIFs for a model for display, or for knitr to process into other formats 
  #' @examples
  #' xkablevif( lm(Salary~Hits+RBI, data=ISLR::Hitters, wide=T ) )
  
  df <- data.frame(vif(model))                            
  names(df) <- "VIF"
  
  if (wide) { df <- t(df) }
  xkabledply(df, title=title, digits = digits, pos=pos, bso=bso )    
}
```

```{r stats_libs, include=F}
loadPkg("leaps")
loadPkg("ggplot2")
loadPkg("caret")
```



```{r data, include=F}
# run this chunk to load data so that we all use same data for training/testing

train <- load_data()
test <- load_data(F)

```
# Introduction


## Goals
1.	Understand which attributes of a home and its sale determine final sale price
2.	Attempt to build a reasonable model for inference and/or prediction for final sale price


## Dataset
- Home Sales in 2017
  - Location
  - Construction
  - Sale
- Variables: 20
  - Numeric: 12
  - Categorical: 8
  


## Exploratory Data Analysis

```{r eda, results='markup'}
hist(test$Price)
```


## New for Project 2

Created 5 `Price` based categories

Imputed missing data based on suburb




# Linear Model Variable Selection
```{r }
loadPkg("dplyr")

# df<-data.frame(read.csv("melb_data.csv"))

df1 <- select(train,
            Price, Distance, Rooms, Bedroom2, Bathroom, Car, 
            Landsize, Lattitude, Longtitude, 
            Propertycount, BuildingArea, YearBuilt)

reg.best5 <- regsubsets(Price~. , data = df1, nvmax = 5, nbest = 1, method = "exhaustive")

plot(reg.best5, scale = "bic", main = "BIC")

mod.select <- lm(Price ~ Distance + Rooms + Lattitude + BuildingArea + YearBuilt, data=train)

p.lm <- predict(mod.select, test)

r.2.lm <- r2(p.lm, test$Price)

mse.lm <- mean((p.lm - test$Price)^2)
```

The best model is based on five variables: `Distance`, `Rooms`, `Lattitude`, `BuildingArea`, `YearBuilt` 




# Regularization: Lasso regression
## Lasso Model
```{r regularization process for data preparation, include= FALSE}
# data for trainning model
train.X <- data.matrix(train[,-which(names(train) %in% c("Price", "Price.cuts"))])
train.y <- data.matrix(log(train$Price))

# data for testing model
test.X <- data.matrix(test[,-which(names(test) %in% c("Price", "Price.cuts"))])
test.y <- data.matrix(log(test$Price))

```


```{r lasso, results='markup'}
loadPkg("glmnet")

lasso <- cv.glmnet(x = train.X, y = train.y, nfolds = 10)

plot(lasso)

```


## Coefficients

```{r coef in lasso regression}

coef(lasso, s = 'lambda.min', exact = TRUE)
min(lasso$cvm)

```

From the coefficient of lasso regression model, the variables of `Rooms`, `Type`, `Distance`, `Postcode`,  `Bathroom`, `YearBuilt`, `Lattitude`, and `Longtitude` are related with response variable `Price`.


## Lasso Results

```{r lasso fit, include=TRUE, results='markup'}
set.seed(999)
lasso_pred <- as.numeric(exp(predict(lasso, newx = test.X, s = "lambda.min"))-1)
hist(lasso_pred, main="Histogram of Lasso Predictions", xlab = "Predictions")

mse_lasso_1 = sum((lasso_pred-exp(test.y))^2)/length(test.y)

r.2.lasso_1 <- r2(lasso_pred, test$Price)
```

## Lasso Prediction

```{r lasso predict, include=TRUE, results='markup'}

plot(exp(test.y),lasso_pred,xlab="True  price",ylab="Predicted price",
     main="Prediction using Lasso regression")

text(-1,3,substitute(r^2 == r2,list(r2=cor(test.y,lasso_pred))),adj=0)
text(-1,2.7,substitute(MSE == r2,list(r2=mse_lasso_1)),adj=0)
abline(0,1)

```


## Lasso Results: Normalized

```{r predict with normalized price, include= TRUE, results='markup'}
lasso_fit = glmnet(train.X,train.y,alpha = 1,lambda = lasso$lambda.min)
pred.y = predict(lasso_fit,test.X)

mse_lasso = mean((exp(pred.y)-exp(test.y))^2)

plot(test.y,pred.y,xlab="True normalized price",ylab="Predicted normalized price",
     main="Prediction using Lasso regression")
text(-1,3,substitute(r^2 == r2,list(r2=cor(test.y,pred.y))),adj=0)
text(-1,2.7,substitute(MSE == r2,list(r2=mse_lasso)),adj=0)
abline(0,1)

r.2.lasso_2 <- r2(exp(pred.y), test$Price)
```






# Tree and Random Forest 

## Tree
```{r tree, results='markup'}
loadPkg("tree")
loadPkg("pROC")


# factors < 32 cats
mod.tree <-tree(factor(Price.cuts)~., 
                data=subset(train, select=-c(Price, SellerG, Suburb, Date, Postcode, CouncilArea)))
  
p <- predict(mod.tree, test, type="class")
  
acc.tree <- sum(p == test$Price.cuts)/length(p)

cm.tree <- confusionMatrix(p, test$Price.cuts)

cm.tree$table

```

Decision trees are usually an easily understood way to associate predictors with an outcome variable. The tree is composed of nodes that represent binary choices based on the dataset variables. When the predictor variable is continuous, the binary decision is a cutoff on the interval of the original variable. Unfortunately, factors with many levels may bias the decision tree to include that variable (Deng, 2011). Considering that some of our categorical variable had many levels, this is a concern for our dataset. Furthermore, the `tree()` function in R only allows variables with up to 32 levels so some variables are excluded from consideration (`SellerG`, `Suburb`, `Date`, `Postcode`, `CouncilArea`). Because of the inclusion of these many-leveled factors even with the worst offenders excluded along with the less descriptive coding of levels, another common benefit of trees is lost to us. Usually, decision trees are easily understood visually but the visualization of this tree is not very helpful. Ultimately, this method gives a middling 

An issue more specific to our dataset is the log-normal distribution of the `Price` data. When splitting the variable into categories, the top five categories were condensed into the top two. This allows each price category to have a reasonable number of observations without making the highest category start its interval at a value more reasonably and colloquially described as average. This places a large majority of the observations in the lowest two categories. Hence, the tree model is able to obtain reasonable accuracy (0.704) by only populating predictions within those lower two categories. So, the model is a bit overfitted and has no prediction ability in the higher prices. 



## Random Forest

### Random Forest: Regression

```{r RF_reg}
loadPkg("randomForest")

# factors < 53 cats
mod.RF <- randomForest(Price~., 
                       data=subset(train, select=-c(Price.cuts, SellerG, Suburb, Date, Postcode)), 
                       importance=T, ntree=200)
  
p.RF_reg <- predict(mod.RF, test)
  
r.2.RF <- r2(p.RF_reg, test$Price)

mse.RF <- mean((p.RF_reg - test$Price)^2)
```

One way to minimize the overfitting of the single tree model to create many trees and take the mean of the outputs predicted from each tree. This is called a random forest model. For our project, we created a random forest that uses 200 trees and 5 variables per tree. Again, the `randomForest()` function in R limits the levels of factors at 53; so (`SellerG`, `Suburb`, `Date`, `Postcode`) are excluded. This greatly improved prediction variance explained ($R^2$ = 0.809) on the test set from previous attempts. Likewise, MSE also improved. 

### Random Forest: Categorical

```{r RF_cats, results='markup'}
# factors < 53 cats
mod.RF.cat <- randomForest(Price.cuts~., 
                           data=subset(train, select=-c(Price, SellerG, Suburb, Date, Postcode)), 
                           importance=T, ntree=200)
  
p <- predict(mod.RF.cat, test)

acc.RF <- sum(p == test$Price.cuts, na.rm=T)/length(p)

mod.RF.cat$confusion

```

This is similar to the regression random forest but uses the mode of the predicted classes among the 200 trees. Otherwise, the setup is the same as the regression model. Although accuracy is greatly improved to 0.831, notice that accuracy for each class varies. Although predictions are placed into the top price categories, the accuracy within those classes is rather low. Most of the accuracy of the model is earned by the lower two levels.  







# k-NN
```{r knn_data_setup, include=FALSE}
#Preparing Training data
train<-train[,c(21,2,12,8,14,17,18,20,19)]
train$Rooms<-as.factor(train$Rooms)

#Creating Dummy Variables for Categorical Variables
loadPkg('fastDummies')
train <- dummy_cols(train, select_columns = 'Rooms')
train <- dummy_cols(train, select_columns = 'Regionname')

train<-train[,-c(2,9)]

#Scaling Numeric Variables
train$Car<- as.numeric(scale(train$Car, center = TRUE, scale = TRUE))
train$Distance<- as.numeric(scale(train$Distance, center = TRUE, scale = TRUE))
train$BuildingArea<- as.numeric(scale(train$BuildingArea, center = TRUE, scale = TRUE))
train$Lattitude<- as.numeric(scale(train$Lattitude, center = TRUE, scale = TRUE))
train$Longtitude<- as.numeric(scale(train$Longtitude, center = TRUE, scale = TRUE))
train$Propertycount<- as.numeric(scale(train$Propertycount, center = TRUE, scale = TRUE))


Rooms_10<-rep(0,nrow(train))
train$Rooms_10<-Rooms_10



#Preparing Testing data
test<-test[,c(21,2,12,8,14,17,18,20,19)]
test$Rooms<-as.factor(test$Rooms)

#Creating Dummy Variables for Categorical Variables
test <- dummy_cols(test, select_columns = 'Rooms')
test <- dummy_cols(test, select_columns = 'Regionname')

test<-test[,-c(2,9)]

#Scaling Numeric Variables
test$Car<- as.numeric(scale(test$Car, center = TRUE, scale = TRUE))
test$Distance<- as.numeric(scale(test$Distance, center = TRUE, scale = TRUE))
test$BuildingArea<- as.numeric(scale(test$BuildingArea, center = TRUE, scale = TRUE))
test$Lattitude<- as.numeric(scale(test$Lattitude, center = TRUE, scale = TRUE))
test$Longtitude<- as.numeric(scale(test$Longtitude, center = TRUE, scale = TRUE))
test$Propertycount<- as.numeric(scale(test$Propertycount, center = TRUE, scale = TRUE))



#Labels
trainLabels <- train[, 1]
testLabels <- test[, 1]

```



```{r knn, include=F}
loadPkg("FNN")

#Model with best total accuracy
mel_pred <- knn(train =train[,-1], test = test[,-1], cl=trainLabels, k=13, prob=T)

loadPkg("caret") 
cm = confusionMatrix(mel_pred, reference = testLabels )
ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )
ResultDf<-ResultDf[nrow(ResultDf)+1,]

ResultDf$k<-13
ResultDf$Total.Accuracy<-cm$overall['Accuracy']
rownames(ResultDf)<-1

```


## Accuracy of k-NN
```{r knn_acc, results="asis"}
xkabledply(ResultDf, "Total Accuracy Summary")
```



## ROC for k-NN
```{r knn_roc, results='asis'}

knn_prob=attributes(mel_pred)$prob
test$knn_prob=knn_prob
h1 <- roc(Price.cuts~knn_prob, data=test)
auc(h1)
plot(h1)
```







# Final Results

## Results for Regression Models
```{r reg_table, results="asis"}

t.reg <- data.frame(rbind(c("BIC Selection", round(r.2.lm, 2), formatC(mse.lm, format="e", digits=2 )),
               c("Lasso", round(r.2.lasso_1,2), formatC(mse_lasso_1, format="e", digits=2 )),
               c("Lasso: Normalized", round(r.2.lasso_2,2), formatC(mse_lasso, format="e", digits=2 )),
               c("Random Forest", round(r.2.RF,2), formatC(mse.RF), format="e", digits=2 ))[,1:3])

names(t.reg) <- c("Method", "R^2", "MSE")
xkabledply(t.reg, title=NULL)
```

The BIC selection mostly confirms the continuous variables that we used in the final linear model for project one. The BIC-chosen model has a testing $R^2$ = 0.45 versus the project one model with $R^2$ = 0.44, marginally worse. Note, however, this is not directly comparable since project one did not have imputed values for missing data as we have here. When we consider the imputed values, the final model from project one has $R^2$ = 0.50 which is likely due to considering a larger subset of variables when making the model. Categorical variables were not included in the BIC selection method. Testing MSE follows a similar pattern ($2.16 \times 10^{11}$ for the imputed project one). As can be seen in the table, lasso regression also did not improve these metrics although it included a larger range of variables.  The best model of those attempted is random forest with a testing proportion of variance explained of $R^2$ = 0.81 and testing MSE = $8.3 \times 10^{10}$, a significant improvement on all regression models. 

## Accuracy for Classifiers
```{r class_table, results="asis"}

t.cat <- data.frame(rbind(c("Tree", round(acc.tree, 3)),
               c("Random Forest", round(acc.RF, 3)),
               c("13-NN", 0.734)))

names(t.cat) <- c("Method", "Accuracy")
xkabledply(t.cat, title=NULL)1
```



# Conclusion



# Bibliography

Deng, Houtao & Runger, George & Tuv, Eugene. (2011). Bias of Importance Measures for Multi-valued Attributes and Solutions. Lecture Notes in Computer Science. 6792. 293-300. 10.1007/978-3-642-21738-8_38.

```{r close_stats_libs, include=F}
# unloadPkg(leaps)
# unloadPkg(ggplot2)
# unloadPkg(gridExtra)
# unloadPkg(scales)
# unloadPkg(heatmaply)
# unloadPkg(Hmisc)
# unloadPkg(faraway)
# unloadPkg(jtools)
```